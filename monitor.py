import requests
from bs4 import BeautifulSoup
import json
import os
from datetime import datetime
import hashlib
import sys
from urllib.parse import urljoin

def load_config():
    """åŠ è½½ç½‘ç«™é…ç½®"""
    with open('sites_config.json', 'r', encoding='utf-8') as f:
        return json.load(f)

def fetch_page_content(url, timeout=30):
    """è·å–ç½‘é¡µå†…å®¹"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    try:
        response = requests.get(url, headers=headers, timeout=timeout)
        response.raise_for_status()
        return response.text
    except Exception as e:
        print(f"è·å–é¡µé¢å¤±è´¥ {url}: {e}")
        return None

def extract_events_generic(html, url, selectors):
    """é€šç”¨çš„äº‹ä»¶æå–å™¨"""
    if not html:
        return []
    
    soup = BeautifulSoup(html, 'html.parser')
    events = []
    
    # å°è¯•ä½¿ç”¨é…ç½®çš„é€‰æ‹©å™¨æŸ¥æ‰¾äº‹ä»¶å®¹å™¨
    containers = []
    for selector in selectors.get('container', []):
        containers.extend(soup.select(selector))
    
    # å¦‚æœæ²¡æ‰¾åˆ°å®¹å™¨ï¼Œå°è¯•ä¸€äº›é€šç”¨çš„é€‰æ‹©å™¨
    if not containers:
        containers = soup.find_all(['article', 'div'], 
                                  class_=lambda x: x and any(word in str(x).lower() 
                                  for word in ['event', 'post', 'item', 'entry']) if x else False)
    
    for container in containers[:20]:  # é™åˆ¶æœ€å¤šå¤„ç†20ä¸ªäº‹ä»¶
        event = {}
        
        # æå–æ ‡é¢˜
        for selector in selectors.get('title', []):
            title = container.select_one(selector)
            if title:
                event['title'] = title.get_text(strip=True)
                break
        
        # æå–æ—¥æœŸ
        for selector in selectors.get('date', []):
            date = container.select_one(selector)
            if date:
                event['date'] = date.get_text(strip=True)
                break
        
        # æå–æè¿°
        for selector in selectors.get('description', []):
            desc = container.select_one(selector)
            if desc:
                event['description'] = desc.get_text(strip=True)[:300]
                break
        
        # æå–é“¾æ¥
        for selector in selectors.get('link', []):
            link_elem = container.select_one(selector)
            if link_elem and link_elem.get('href'):
                event['link'] = urljoin(url, link_elem['href'])
                break
        
        # åªæ·»åŠ è‡³å°‘æœ‰æ ‡é¢˜çš„äº‹ä»¶
        if event.get('title'):
            events.append(event)
    
    # å¦‚æœæ²¡æ‰¾åˆ°ç»“æ„åŒ–çš„äº‹ä»¶ï¼Œè¿”å›é¡µé¢å†…å®¹çš„hashç”¨äºå˜åŒ–æ£€æµ‹
    if not events:
        text_content = soup.get_text()
        page_hash = hashlib.md5(text_content.encode()).hexdigest()[:16]
        events = [{'page_hash': page_hash, 'content_preview': text_content[:500].replace('\n', ' ')}]
    
    return events

def fetch_site_events(site_config):
    """è·å–å•ä¸ªç½‘ç«™çš„äº‹ä»¶"""
    print(f"æ­£åœ¨æ£€æŸ¥: {site_config['name']}")
    
    html = fetch_page_content(site_config['url'])
    if not html:
        return None
    
    events = extract_events_generic(html, site_config['url'], site_config.get('selectors', {}))
    
    # ä¸ºæ¯ä¸ªäº‹ä»¶æ·»åŠ æ¥æºä¿¡æ¯
    for event in events:
        event['source'] = site_config['name']
        event['source_url'] = site_config['url']
    
    return events

def load_last_events():
    """åŠ è½½ä¸Šæ¬¡ä¿å­˜çš„äº‹ä»¶"""
    if os.path.exists('last_events.json'):
        with open('last_events.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def save_events(all_events):
    """ä¿å­˜å½“å‰äº‹ä»¶"""
    with open('last_events.json', 'w', encoding='utf-8') as f:
        json.dump(all_events, f, ensure_ascii=False, indent=2)

def find_new_events(current_events, last_events, site_name):
    """æ‰¾å‡ºæ–°å¢çš„äº‹ä»¶"""
    last_site_events = last_events.get(site_name, [])
    
    # è½¬æ¢ä¸ºå¯æ¯”è¾ƒçš„é›†åˆ
    last_set = {json.dumps(e, sort_keys=True) for e in last_site_events}
    current_set = {json.dumps(e, sort_keys=True) for e in current_events}
    
    new_set = current_set - last_set
    new_events = [json.loads(e) for e in new_set]
    
    return new_events

def format_email_body(all_new_events):
    """æ ¼å¼åŒ–é‚®ä»¶å†…å®¹"""
    if not any(all_new_events.values()):
        return "æœ¬å‘¨æ²¡æœ‰æ£€æµ‹åˆ°æ–°äº‹ä»¶"
    
    total_count = sum(len(events) for events in all_new_events.values())
    body = f"# ğŸ“… æœ¬å‘¨äº‹ä»¶æ›´æ–°æ±‡æ€»\n\n"
    body += f"æ£€æµ‹åˆ° **{total_count}** ä¸ªæ–°äº‹ä»¶/æ›´æ–°\n\n"
    body += f"æ£€æŸ¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} UTC\n\n"
    body += "---\n\n"
    
    for site_name, events in all_new_events.items():
        if not events:
            continue
            
        body += f"## ğŸ“Œ {site_name}\n\n"
        
        for i, event in enumerate(events, 1):
            if 'page_hash' in event:
                body += f"**âš¡ é¡µé¢å†…å®¹å·²æ›´æ–°**\n"
                if 'content_preview' in event:
                    body += f"é¢„è§ˆ: {event['content_preview'][:200]}...\n\n"
                body += f"æŸ¥çœ‹å®Œæ•´é¡µé¢: {event.get('source_url', '')}\n\n"
            else:
                body += f"### äº‹ä»¶ {i}\n"
                if 'title' in event:
                    body += f"**{event['title']}**\n\n"
                if 'date' in event:
                    body += f"ğŸ“… æ—¶é—´: {event['date']}\n\n"
                if 'description' in event:
                    desc = event['description']
                    if len(desc) > 200:
                        desc = desc[:200] + "..."
                    body += f"ğŸ“ æè¿°: {desc}\n\n"
                if 'link' in event:
                    body += f"ğŸ”— é“¾æ¥: {event['link']}\n\n"
            
            body += "---\n\n"
    
    # æ·»åŠ ç›‘æ§çš„ç½‘ç«™åˆ—è¡¨
    body += "## ğŸ“Š ç›‘æ§çš„ç½‘ç«™\n\n"
    config = load_config()
    for site in config['sites']:
        if site.get('enabled', True):
            body += f"- [{site['name']}]({site['url']})\n"
    
    return body

def main():
    print("="*50)
    print("å¼€å§‹æ£€æŸ¥ç½‘ç«™æ›´æ–°...")
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*50)
    
    config = load_config()
    sites = [s for s in config['sites'] if s.get('enabled', True)]
    
    print(f"å°†æ£€æŸ¥ {len(sites)} ä¸ªç½‘ç«™\n")
    
    # åŠ è½½ä¸Šæ¬¡çš„äº‹ä»¶
    last_events = load_last_events()
    
    # æ”¶é›†æ‰€æœ‰ç½‘ç«™çš„äº‹ä»¶
    current_all_events = {}
    all_new_events = {}
    
    for site in sites:
        # è·å–å½“å‰äº‹ä»¶
        current_events = fetch_site_events(site)
        
        if current_events is None:
            print(f"âš ï¸  è·³è¿‡ {site['name']} (è·å–å¤±è´¥)\n")
            continue
        
        print(f"âœ“ æ‰¾åˆ° {len(current_events)} ä¸ªäº‹ä»¶/å†…å®¹")
        
        site_name = site['name']
        current_all_events[site_name] = current_events
        
        # æ‰¾å‡ºæ–°äº‹ä»¶
        new_events = find_new_events(current_events, last_events, site_name)
        if new_events:
            print(f"  ğŸ†• å‘ç° {len(new_events)} ä¸ªæ–°äº‹ä»¶/æ›´æ–°ï¼")
            all_new_events[site_name] = new_events
        else:
            print(f"  æ²¡æœ‰æ–°æ›´æ–°")
        
        print()
    
    # å¤„ç†ç»“æœ
    total_new = sum(len(events) for events in all_new_events.values())
    
    if total_new > 0:
        print(f"\nğŸ‰ æ€»è®¡å‘ç° {total_new} ä¸ªæ›´æ–°ï¼")
        
        # ç”Ÿæˆé‚®ä»¶å†…å®¹
        email_body = format_email_body(all_new_events)
        
        # ä¿å­˜é‚®ä»¶å†…å®¹
        with open('email_content.txt', 'w', encoding='utf-8') as f:
            f.write(email_body)
        
        print("\né‚®ä»¶å†…å®¹å·²ç”Ÿæˆ")
        
        # è®¾ç½®GitHub Actionsè¾“å‡º
        print(f"::set-output name=has_updates::true")
        print(f"::set-output name=update_count::{total_new}")
        
        # ä¿å­˜å½“å‰äº‹ä»¶
        save_events(current_all_events)
        
        # æäº¤æ›´æ”¹åˆ°Git
        os.system('git config --local user.email "action@github.com"')
        os.system('git config --local user.name "GitHub Action"')
        os.system('git add last_events.json')
        os.system('git commit -m "Update events cache"')
    else:
        print("\næ²¡æœ‰å‘ç°æ–°æ›´æ–°")
        print(f"::set-output name=has_updates::false")
        print(f"::set-output name=update_count::0")
        
        # å³ä½¿æ²¡æœ‰æ–°äº‹ä»¶ä¹Ÿæ›´æ–°ç¼“å­˜ï¼ˆé˜²æ­¢ç½‘ç«™ç»“æ„å˜åŒ–å¯¼è‡´çš„è¯¯æŠ¥ï¼‰
        if current_all_events:
            save_events(current_all_events)

if __name__ == "__main__":
    main()